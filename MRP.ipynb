{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackDigout/MRP/blob/main/MRP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHdlUp0cpVIM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class DGMNet(tf.keras.Model):\n",
        "    def __init__(self, n_layers, layer_width, input_dim):\n",
        "        super(DGMNet, self).__init__()\n",
        "        self.initial_layer = DenseLayer(input_dim + 1, layer_width, activation=\"tanh\")\n",
        "        self.n_layers = n_layers\n",
        "        self.LSTMLayerList = [LSTMLayer(input_dim + 1, layer_width, activation=\"tanh\") for _ in range(n_layers)]\n",
        "        self.final_layer = DenseLayer(layer_width, 1, activation=None)\n",
        "\n",
        "    def call(self, x, t):\n",
        "        X = tf.concat([x, tf.cast(t, tf.float32)], 1)\n",
        "        S = self.initial_layer(X)\n",
        "        for lstm_layer in self.LSTMLayerList:\n",
        "            S = lstm_layer(S, X)\n",
        "        result = self.final_layer(S)\n",
        "        return result\n",
        "\n",
        "class LSTMLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_inputs, n_outputs, activation):\n",
        "        super(LSTMLayer, self).__init__()\n",
        "        self.n_outputs = n_outputs\n",
        "        self.n_inputs = n_inputs\n",
        "        self.activation = _get_function(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.Uz = self.add_weight(name=\"Uz\", shape=[self.n_inputs, self.n_outputs], dtype=tf.float32,\n",
        "                                  initializer=tf.keras.initializers.glorot_uniform())\n",
        "        self.Ug = self.add_weight(name=\"Ug\", shape=[self.n_inputs, self.n_outputs], dtype=tf.float32,\n",
        "                                  initializer=tf.keras.initializers.glorot_uniform())\n",
        "        self.Ur = self.add_weight(name=\"Ur\", shape=[self.n_inputs, self.n_outputs], dtype=tf.float32,\n",
        "                                  initializer=tf.keras.initializers.glorot_uniform())\n",
        "        self.Uh = self.add_weight(name=\"Uh\", shape=[self.n_inputs, self.n_outputs], dtype=tf.float32,\n",
        "                                  initializer=tf.keras.initializers.glorot_uniform())\n",
        "        self.Wz = self.add_weight(name=\"Wz\", shape=[self.n_outputs, self.n_outputs], dtype=tf.float32,\n",
        "                                  initializer=tf.keras.initializers.glorot_uniform())\n",
        "        self.Wg = self.add_weight(name=\"Wg\", shape=[self.n_outputs, self.n_outputs], dtype=tf.float32,\n",
        "                                  initializer=tf.keras.initializers.glorot_uniform())\n",
        "        self.Wr = self.add_weight(name=\"Wr\", shape=[self.n_outputs, self.n_outputs], dtype=tf.float32,\n",
        "                                  initializer=tf.keras.initializers.glorot_uniform())\n",
        "        self.Wh = self.add_weight(name=\"Wh\", shape=[self.n_outputs, self.n_outputs], dtype=tf.float32,\n",
        "                                  initializer=tf.keras.initializers.glorot_uniform())\n",
        "        self.bz = self.add_weight(name=\"bz\", shape=[self.n_outputs], dtype=tf.float32)\n",
        "        self.bg = self.add_weight(name=\"bg\", shape=[self.n_outputs], dtype=tf.float32)\n",
        "        self.br = self.add_weight(name=\"br\", shape=[self.n_outputs], dtype=tf.float32)\n",
        "        self.bh = self.add_weight(name=\"bh\", shape=[self.n_outputs], dtype=tf.float32)\n",
        "        super(LSTMLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, S, X):\n",
        "        Z = self.activation(tf.add(tf.add(tf.matmul(X, self.Uz), tf.matmul(S, self.Wz)), self.bz))\n",
        "        G = self.activation(tf.add(tf.add(tf.matmul(X, self.Ug), tf.matmul(S, self.Wg)), self.bg))\n",
        "        R = self.activation(tf.add(tf.add(tf.matmul(X, self.Ur), tf.matmul(S, self.Wr)), self.br))\n",
        "        H = self.activation(tf.add(tf.add(tf.matmul(X, self.Uh), tf.matmul(tf.multiply(S, R), self.Wh)), self.bh))\n",
        "        Snew = tf.add(tf.multiply(tf.subtract(tf.ones_like(G), G), H), tf.multiply(Z, S))\n",
        "        return Snew\n",
        "\n",
        "class DenseLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, n_inputs, n_outputs, activation):\n",
        "        super(DenseLayer, self).__init__()\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_outputs = n_outputs\n",
        "        self.activation = _get_function(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name=\"W\", shape=[self.n_inputs, self.n_outputs], dtype=tf.float32,\n",
        "                                 initializer=tf.keras.initializers.glorot_uniform())\n",
        "        self.b = self.add_weight(name=\"b\", shape=[self.n_outputs], dtype=tf.float32)\n",
        "        super(DenseLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        S = tf.add(tf.matmul(inputs, self.W), self.b)\n",
        "        return self.activation(S)\n",
        "\n",
        "def _get_function(name):\n",
        "    if name == \"tanh\":\n",
        "        return tf.nn.tanh\n",
        "    elif name == \"sigmoid\":\n",
        "        return tf.nn.sigmoid\n",
        "    elif name == \"relu\":\n",
        "        return tf.nn.relu\n",
        "    elif not name:\n",
        "        return tf.identity\n",
        "    raise ValueError(f\"Unsupported activation function: {name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMBhjeGRlbNo"
      },
      "outputs": [],
      "source": [
        "class DomainNd:\n",
        "\n",
        "    def __init__(self, range_vec, T):\n",
        "        self.dim = len(range_vec)\n",
        "        self.range_vec = range_vec\n",
        "        self.lower_bound = range_vec.T[0]\n",
        "        self.upper_bound = range_vec.T[1]\n",
        "        self.T = T\n",
        "\n",
        "    def get_discretization_size(self, n_vec, nt):\n",
        "        return (self.range_vec[:, 1] - self.range_vec[:, 0]) / n_vec, self.T / nt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Kt1BYvNR2-"
      },
      "outputs": [],
      "source": [
        "class SamplerNd:\n",
        "\n",
        "    def __init__(self, domainNd, multi):\n",
        "        self.domain = domainNd\n",
        "        self.multi = multi\n",
        "\n",
        "    def run(self, n_interior, n_terminal):\n",
        "        # Sampler #1: domain interior\n",
        "        dim, T = self.domain.dim, self.domain.T\n",
        "        lower_bound, upper_bound = self.domain.lower_bound, self.domain.upper_bound * self.multi\n",
        "        t_interior = np.random.uniform(low=0, high=T-1e-10, size=[n_interior, 1])\n",
        "        S_interior = np.random.uniform(low=lower_bound, high=upper_bound, size=[n_interior, dim])\n",
        "\n",
        "\n",
        "\n",
        "        # Sampler #2: initial/terminal condition\n",
        "        t_terminal = T * np.ones((n_terminal, 1))\n",
        "        S_terminal = np.random.uniform(low=lower_bound, high=upper_bound, size=[n_terminal, dim])\n",
        "\n",
        "        return S_interior, t_interior, S_terminal, t_terminal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxeUD_x5YS3F"
      },
      "outputs": [],
      "source": [
        "class SamplerNdV2:\n",
        "    def __init__(self, domainNd, multi):\n",
        "        self.domain = domainNd\n",
        "        self.multi = multi\n",
        "\n",
        "    def run(self, n_interior, n_terminal, n_boundary):\n",
        "        # Sampler #1: domain interior\n",
        "        dim, T = self.domain.dim, self.domain.T\n",
        "        lower_bound, upper_bound = self.domain.lower_bound, self.domain.upper_bound * self.multi\n",
        "        t_interior = np.random.uniform(low=0, high=T - 1e-10, size=[n_interior, 1])\n",
        "        S_interior = np.random.uniform(low=lower_bound, high=upper_bound, size=[n_interior, dim])\n",
        "\n",
        "        # Sampler #2: terminal condition\n",
        "        t_terminal = T * np.ones((n_terminal, 1))\n",
        "        S_terminal = np.random.uniform(low=lower_bound, high=upper_bound, size=[n_terminal, dim])\n",
        "\n",
        "        # Sampler #3: boundary conditions\n",
        "        # At S = 0\n",
        "        S_boundary_zero = np.zeros((n_boundary, dim))  # S = 0\n",
        "        t_boundary_zero = np.random.uniform(low=0, high=T - 1e-10, size=[n_boundary, 1])  # random times\n",
        "\n",
        "        # At S = S_max (or some large value)\n",
        "        S_boundary_max = np.ones((n_boundary, dim)) * upper_bound  # S = S_max\n",
        "        t_boundary_max = np.random.uniform(low=0, high=T - 1e-10, size=[n_boundary, 1])  # random times\n",
        "\n",
        "        return (S_interior, t_interior, S_terminal, t_terminal,\n",
        "                S_boundary_zero, t_boundary_zero,\n",
        "                S_boundary_max, t_boundary_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR-Bngc1Zv1D"
      },
      "outputs": [],
      "source": [
        "class AmerSamplerNdV2:\n",
        "    def __init__(self, domainNd, multi):\n",
        "        self.domain = domainNd\n",
        "        self.multi = multi\n",
        "\n",
        "    def run(self, n_interior, n_terminal, n_boundary):\n",
        "        # Sampler #1: domain interior\n",
        "        dim, T = self.domain.dim, self.domain.T\n",
        "        lower_bound, upper_bound = self.domain.lower_bound, self.domain.upper_bound * self.multi\n",
        "        t_interior = np.random.uniform(low=0, high=T - 1e-10, size=[n_interior, 1])\n",
        "        S_interior = np.random.uniform(low=lower_bound, high=upper_bound, size=[n_interior, dim])\n",
        "\n",
        "        # Sampler #2: terminal condition\n",
        "        t_terminal = T * np.ones((n_terminal, 1))\n",
        "        S_terminal = np.random.uniform(low=lower_bound, high=upper_bound, size=[n_terminal, dim])\n",
        "\n",
        "        # Sampler #3: boundary conditions\n",
        "        # At S = 0\n",
        "        S_boundary_zero = 50 * np.ones((n_boundary, dim))  # S = 0\n",
        "        t_boundary_zero = np.random.uniform(low=0, high=T - 1e-10, size=[n_boundary, 1])  # random times\n",
        "\n",
        "        # # At S = S_max (or some large value)\n",
        "        # S_boundary_infinity = np.ones((n_boundary, dim)) * upper_bound  # S = S_max\n",
        "        # t_boundary_infinity = np.random.uniform(low=0, high=T - 1e-10, size=[n_boundary, 1])  # random times\n",
        "\n",
        "        return S_interior, t_interior, S_terminal, t_terminal, S_boundary_zero, t_boundary_zero,\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GYss8Am7P_C"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import qmc\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy.stats.qmc import Sobol\n",
        "class SobolSamplerNd:\n",
        "    def __init__(self, domainNd):\n",
        "        self.domain = domainNd\n",
        "\n",
        "    def run(self, n_interior, n_terminal, n_boundary):\n",
        "        # Sobol sampler for domain interior\n",
        "        dim, T = self.domain.dim, self.domain.T\n",
        "        lower_bound, upper_bound = self.domain.lower_bound, self.domain.upper_bound * 1.3\n",
        "        sobol_sampler = Sobol(d=dim + 1, scramble=True)\n",
        "\n",
        "        sobol_interior = sobol_sampler.random(n_interior)\n",
        "        t_interior = sobol_interior[:, 0].reshape(- 1, 1) * (T - 1e-10)\n",
        "        S_interior = sobol_interior[:, 1:] * (upper_bound - lower_bound) + lower_bound\n",
        "\n",
        "        S_boundary_zero = np.zeros((n_boundary, dim))  # S = 0\n",
        "        t_boundary_zero = np.random.uniform(low=0, high=T - 1e-10, size=[n_boundary, 1])\n",
        "\n",
        "        S_boundary_max = np.ones((n_boundary, dim)) * upper_bound  # S = S_max\n",
        "        t_boundary_max = np.random.uniform(low=0, high=T - 1e-10, size=[n_boundary, 1])  # random times\n",
        "\n",
        "        # Sobol sampler for initial/terminal condition\n",
        "        sobol_terminal = sobol_sampler.random(n_terminal)\n",
        "        t_terminal = T * np.ones((n_terminal, 1))\n",
        "        # Extract the spatial dimensions for terminal points, ensuring consistency with t_terminal\n",
        "        S_terminal = sobol_terminal[:, 1:] * (upper_bound - lower_bound) + lower_bound\n",
        "\n",
        "        return S_interior, t_interior, S_terminal, t_terminal, S_boundary_zero, t_boundary_zero, S_boundary_max, t_boundary_max\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEyFZW2tPUk5"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from scipy.stats import norm\n",
        "T = 1\n",
        "def BSM(S, K, r, sigma, t, q):\n",
        "    ''' Analytical solution for European call option price under Black-Scholes model\n",
        "\n",
        "    Args:\n",
        "        S:     spot price\n",
        "        K:     strike price\n",
        "        r:     risk-free interest rate\n",
        "        sigma: volatility\n",
        "        t:     time\n",
        "    '''\n",
        "\n",
        "    d1 = (np.log(S/K) + (r - q + sigma**2 / 2) * (T-t))/(sigma * np.sqrt(T-t))\n",
        "    d2 = d1 - (sigma * np.sqrt(T-t))\n",
        "\n",
        "    callPrice = S * np.exp(-q * (T-t)) * norm.cdf(d1) - K * np.exp(-r * (T-t)) * norm.cdf(d2)\n",
        "    putPrice = K * np.exp(-r * (T-t)) * norm.cdf(-d2) - S * np.exp(-q * (T-t)) * norm.cdf(-d1)\n",
        "\n",
        "    return callPrice, putPrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3RWJWevv2E8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "T = 1\n",
        "def margrabe(S1, S2, vol1, vol2, rho, q1, q2, t):\n",
        "      \"\"\"\n",
        "      Calculates the price of an option to exchange one asset for another,\n",
        "      considering dividend yields.\n",
        "\n",
        "      Args:\n",
        "        S1: Price of asset 1.\n",
        "        S2: Price of asset 2.\n",
        "        vol1: Volatility of asset 1.\n",
        "        vol2: Volatility of asset 2.\n",
        "        rho: Correlation between the returns of asset 1 and asset 2.\n",
        "        q1: Dividend yield of asset 1.\n",
        "        q2: Dividend yield of asset 2.\n",
        "        T: Time to maturity.\n",
        "\n",
        "      Returns:\n",
        "        The price of the Margrabe option with dividends.\n",
        "      \"\"\"\n",
        "\n",
        "      sigma = np.sqrt(vol1**2 + vol2**2 - 2 * rho * vol1 * vol2)\n",
        "      d1 = (np.log(S1/S2) + (q1 - q2 + sigma**2 / 2) * (T-t))/(sigma * np.sqrt(T-t))\n",
        "      d2 = d1 - (sigma * np.sqrt(T-t))\n",
        "\n",
        "      callPrice = S1 * np.exp(-q1 * (T-t)) * norm.cdf(d1) - S2 * np.exp(-q2 * (T-t)) * norm.cdf(d2)\n",
        "\n",
        "      return callPrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noMdx32p-l5s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SamplerHeston:\n",
        "    def __init__(self, domainNd, v0, kappa, theta, xi, rho):\n",
        "        self.domain = domainNd\n",
        "        self.v0 = v0  # Initial variance\n",
        "        self.kappa = kappa\n",
        "        self.theta = theta\n",
        "        self.xi = xi\n",
        "        self.rho = rho\n",
        "\n",
        "    def run(self, n_interior, n_terminal):\n",
        "        dim, T = self.domain.dim, self.domain.T\n",
        "        lower_bound, upper_bound = self.domain.lower_bound, self.domain.upper_bound*1.3\n",
        "\n",
        "        # Sample times\n",
        "        t_interior = np.random.uniform(low=0, high=T-1e-10, size=[n_interior, 1])\n",
        "        t_terminal = T * np.ones((n_terminal, 1))\n",
        "\n",
        "        # Sample asset prices\n",
        "        S_interior = np.random.uniform(low=lower_bound, high=upper_bound, size=[n_interior, dim])\n",
        "        S_terminal = np.random.uniform(low=lower_bound, high=upper_bound, size=[n_terminal, dim])\n",
        "\n",
        "        # Sample variances\n",
        "        V_interior = self.sample_variance(n_interior)\n",
        "        V_terminal = self.sample_variance(n_terminal)\n",
        "\n",
        "        return S_interior, V_interior, t_interior, S_terminal, V_terminal, t_terminal\n",
        "\n",
        "    def sample_variance(self, n_samples):\n",
        "        # Sample variances according to the Heston model dynamics\n",
        "        # Here, we use a simple mean-reverting process for illustration\n",
        "        variances = self.theta + (self.v0 - self.theta) * np.exp(-self.kappa * np.random.uniform(size=n_samples)) \\\n",
        "                    + self.xi * np.sqrt((1 - np.exp(-2 * self.kappa * np.random.uniform(size=n_samples))) / (2 * self.kappa))\n",
        "        return np.maximum(variances, 0).reshape(-1, 1)  # Ensure non-negative variances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KvkkvL9PAja"
      },
      "outputs": [],
      "source": [
        "import sys, os, time\n",
        "DIR_LOC = os.getcwd()\n",
        "sys.path.append(DIR_LOC+\"/..\")\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "class American:\n",
        "    def __init__(self, payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, strike, sampler=None):\n",
        "        self.payoff_func = payoff_func\n",
        "        self.domain = domain\n",
        "        self.dim = domain.dim\n",
        "        self.vol_vec = vol_vec\n",
        "        self.ir = ir\n",
        "        self.dividend_vec = dividend_vec\n",
        "        self.corr_mat = corr_mat\n",
        "        self.strike = strike\n",
        "        self.cov_mat = np.outer(vol_vec, vol_vec) * corr_mat\n",
        "        self.sampler = sampler if sampler is not None else SamplerNd(domain)\n",
        "        self.model = None\n",
        "\n",
        "    def run(self, n_samples, steps_per_sample, n_layers=3, layer_width=50, n_interior=16,\n",
        "            n_boundary=16, n_terminal=32):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        model = DGMNet(n_layers, layer_width, input_dim=self.dim)\n",
        "        self.model = model\n",
        "\n",
        "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-2, decay_steps=1000, decay_rate=0.9)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "        self.loss_vec, self.L1_vec, self.L2_vec, self.L3_vec, self.L4_vec = [], [], [], [], []\n",
        "\n",
        "        @tf.function\n",
        "        def train_step(S_interior, t_interior, S_terminal, t_terminal):\n",
        "            with tf.GradientTape(persistent=True) as tape:\n",
        "                tape.watch([S_interior, t_interior])\n",
        "                loss, L1, L2, L3, L4 = self.compute_loss(model, S_interior, t_interior, S_terminal, t_terminal)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "            return loss, L1, L2, L3, L4\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            S_interior, t_interior, S_terminal, t_terminal = self.sampler.run(n_interior, n_terminal)\n",
        "            S_interior = tf.convert_to_tensor(S_interior, dtype=tf.float32)\n",
        "            t_interior = tf.convert_to_tensor(t_interior, dtype=tf.float32)\n",
        "            S_terminal = tf.convert_to_tensor(S_terminal, dtype=tf.float32)\n",
        "            t_terminal = tf.convert_to_tensor(t_terminal, dtype=tf.float32)\n",
        "\n",
        "            for _ in range(steps_per_sample):\n",
        "                loss, L1, L2, L3, L4 = train_step(S_interior, t_interior, S_terminal, t_terminal)\n",
        "\n",
        "            self.loss_vec.append(loss.numpy())\n",
        "            self.L1_vec.append(L1.numpy())\n",
        "            self.L2_vec.append(L2.numpy())\n",
        "            self.L4_vec.append(L3.numpy())\n",
        "            self.L4_vec.append(L4.numpy())\n",
        "\n",
        "            if i % 10 == 0:\n",
        "              print(f\"Iteration {i}: Loss: {loss.numpy()}; L1: {L1.numpy()}; L2: {L2.numpy()}; L3: {L3.numpy()}; L4: {L4.numpy()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if self.dim == 1:\n",
        "            self.plot_results(self.model)\n",
        "\n",
        "        if self.dim == 2:\n",
        "            self.checkExchange(model)\n",
        "\n",
        "        plt.plot(np.log(self.loss_vec))\n",
        "        plt.xlabel('Sampling Stage')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss over Time')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        S0 = np.full((1, self.dim), 25, dtype=np.float32)\n",
        "        t0 = np.array([[0]])  # Time to maturity\n",
        "        value_at_S0 = model(S0, t0).numpy()\n",
        "        print(\"Option Value at S0 = 1.5 for all assets:\", value_at_S0)\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, model, S_interior, t_interior, S_terminal, t_terminal):\n",
        "        S_interior = tf.convert_to_tensor(S_interior, dtype=tf.float32)\n",
        "        t_interior = tf.convert_to_tensor(t_interior, dtype=tf.float32)\n",
        "        S_terminal = tf.convert_to_tensor(S_terminal, dtype=tf.float32)\n",
        "        t_terminal = tf.convert_to_tensor(t_terminal, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape1:\n",
        "            tape1.watch([S_interior, t_interior])\n",
        "            with tf.GradientTape() as tape2:\n",
        "                tape2.watch([S_interior, t_interior])\n",
        "                V = model(S_interior, t_interior)\n",
        "            V_s = tape2.gradient(V, S_interior)\n",
        "        V_ss = tape1.batch_jacobian(V_s, S_interior)\n",
        "\n",
        "        with tf.GradientTape() as tape3:\n",
        "            tape3.watch([S_interior, t_interior])\n",
        "            V = model(S_interior, t_interior)\n",
        "        V_t = tape3.gradient(V, t_interior)\n",
        "\n",
        "        sec_ord = 0\n",
        "        for i in range(self.dim):\n",
        "            for j in range(self.dim):\n",
        "                S_coli = tf.reshape(S_interior[:, i], [-1, 1])\n",
        "                S_colj = tf.reshape(S_interior[:, j], [-1, 1])\n",
        "                V_ss_column = tf.reshape(V_ss[:, i, j], [-1, 1])\n",
        "                sec_ord += self.vol_vec[i] * self.vol_vec[j] * self.corr_mat[i, j] * S_coli * S_colj * V_ss_column\n",
        "\n",
        "        fir_ord = 0\n",
        "        for i in range(self.dim):\n",
        "            V_s_column = tf.reshape(V_s[:, i], [-1, 1])\n",
        "            S_col1 = tf.reshape(S_interior[:, i], [-1, 1])\n",
        "            fir_ord += (self.ir - self.dividend_vec[i]) * S_col1 * V_s_column\n",
        "\n",
        "        diff_V = V_t + 0.5 * sec_ord + fir_ord - self.ir * V\n",
        "\n",
        "        payoff = tf.nn.relu(self.strike - S_interior)\n",
        "        value = model(S_interior, t_interior)\n",
        "        L1 = tf.reduce_mean(tf.square( diff_V * (value - payoff) ))\n",
        "\n",
        "        temp = tf.nn.relu(diff_V)                   # Minimizes -min(-f,0) = max(f,0)\n",
        "        L2 = tf.reduce_mean(tf.square(temp))\n",
        "\n",
        "        # V_boundary_zero = model(self.strike, t_interior)\n",
        "        # L_boundary_zero = tf.reduce_mean(tf.square(V_boundary_zero))\n",
        "\n",
        "        V_ineq = tf.nn.relu(-(value-payoff))      # Minimizes -min(-f,0) = max(f,0)\n",
        "        L3 = tf.reduce_mean(tf.square(V_ineq))\n",
        "\n",
        "        target_payoff = tf.nn.relu(self.strike - S_terminal)\n",
        "        fitted_payoff = model(S_terminal, t_terminal)\n",
        "\n",
        "        L4 = tf.reduce_mean( tf.square(fitted_payoff - target_payoff) )\n",
        "        total_loss = L1 + L2 + L3 + L4\n",
        "        return total_loss, L1, L2, L3, L4\n",
        "\n",
        "    def plot_results(self, model):\n",
        "        S_plot = np.linspace(self.domain.lower_bound, self.domain.upper_bound, 100).reshape(-1, 1)\n",
        "        S_plot1 = np.linspace(self.domain.lower_bound, self.domain.upper_bound, 100)\n",
        "        fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
        "        fig_error, axs_error = plt.subplots(2, 2, figsize=(12, 10))\n",
        "        error = np.zeros((100, 4))\n",
        "        total_error = np.zeros((1, 4))\n",
        "\n",
        "        # Time values at which to examine density\n",
        "        valueTimes = [0, 1/3, 2/3, 1]\n",
        "\n",
        "        for i, curr_t in enumerate(valueTimes):\n",
        "            # Specify subplot\n",
        "            ax = axs[i//2, i%2]\n",
        "\n",
        "            # Simulate process at current t\n",
        "            S = np.zeros((100, 1))\n",
        "            for j in range(100):\n",
        "                if i < 3:\n",
        "                    S[j, 0] = AmericanBinom(j, self.strike, 1.0 - curr_t, self.ir, self.vol_vec[0], self.dividend_vec[0])\n",
        "                else:\n",
        "                    S[j, 0] = np.maximum((self.strike - S_plot1[j]), 0)\n",
        "\n",
        "\n",
        "            # for j in range(100):\n",
        "            #     k = j+1.0\n",
        "            #     S[j, 0] = AmericanOptionsLSMC('put', k, 50., 1., 50, 0.04, 0.01, 0.15, 1000).price\n",
        "\n",
        "            # Compute normalized density at all x values to plot and current t value\n",
        "            t_plot = np.full(S_plot.shape, curr_t, dtype=np.float32)\n",
        "            value = model(S_plot, t_plot).numpy()\n",
        "\n",
        "            # Calculate error\n",
        "            current_error = np.abs(value - S)\n",
        "            error[:, i] = current_error.flatten()  # Store the error for each point\n",
        "            total_error[0, i] = np.sum(current_error)  # Compute the mean error for current t\n",
        "\n",
        "\n",
        "            # Plot analytical solution and DGM estimate\n",
        "            ax.plot(S_plot, S, color='b', label='Binomial tree estimate', linewidth=3, linestyle=':')\n",
        "            ax.plot(S_plot, value, color='r', label='Network estimate')\n",
        "\n",
        "            # Subplot options\n",
        "            ax.set_xlabel(\"Spot Price\", fontsize=15, labelpad=10)\n",
        "            ax.set_ylabel(\"Option Price\", fontsize=15, labelpad=20)\n",
        "\n",
        "            ax.tick_params(axis='both', which='major', labelsize=13)\n",
        "            ax.grid(linestyle=':')\n",
        "\n",
        "            if i == 0:\n",
        "                ax.legend(loc='upper left', prop={'size': 16})\n",
        "\n",
        "            # Plot error in separate subplot\n",
        "            ax_error = axs_error[i//2, i%2]\n",
        "            ax_error.plot(S_plot, current_error, color='g', label='Error', linestyle='--')\n",
        "\n",
        "            # Subplot options for error\n",
        "            ax_error.set_xlabel(\"Spot Price\", fontsize=15, labelpad=10)\n",
        "            ax_error.set_ylabel(\"Error\", fontsize=15, labelpad=20)\n",
        "            ax_error.set_title(\"Absolute Error\", fontsize=18, y=1.03)\n",
        "\n",
        "            ax_error.tick_params(axis='both', which='major', labelsize=13)\n",
        "            ax_error.grid(linestyle=':')\n",
        "\n",
        "            if i == 0:\n",
        "                ax_error.legend(loc='upper left', prop={'size': 16})\n",
        "\n",
        "        # Adjust space between subplots\n",
        "        fig.subplots_adjust(wspace=0.3, hspace=0.4)\n",
        "        fig_error.subplots_adjust(wspace=0.3, hspace=0.4)\n",
        "        print(total_error)\n",
        "        # Optionally, print or return the error arrays if needed\n",
        "\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK9OveT9P-oE"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "\n",
        "class CEV:\n",
        "    def __init__(self, payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, beta, strike, sampler=None):\n",
        "        self.payoff_func = payoff_func\n",
        "        self.domain = domain\n",
        "        self.dim = domain.dim\n",
        "        self.vol_vec = vol_vec\n",
        "        self.ir = ir\n",
        "        self.dividend_vec = dividend_vec\n",
        "        self.corr_mat = corr_mat\n",
        "        self.beta = beta\n",
        "        self.strike = strike\n",
        "        self.cov_mat = np.outer(vol_vec, vol_vec) * corr_mat\n",
        "        self.sampler = sampler if sampler is not None else SamplerNd(domain)\n",
        "\n",
        "    def run(self, n_samples, steps_per_sample, n_layers=3, layer_width=50, n_interior=16,\n",
        "            n_boundary=16, n_terminal=32):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        model = DGMNet(n_layers, layer_width, input_dim=self.dim)\n",
        "        self.model = model\n",
        "\n",
        "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-2, decay_steps=1000, decay_rate=0.9)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "        self.loss_vec, self.L1_vec, self.L3_vec = [], [], []\n",
        "\n",
        "        @tf.function\n",
        "        def train_step(S_interior, t_interior, S_terminal, t_terminal):\n",
        "            with tf.GradientTape(persistent=True) as tape:\n",
        "                tape.watch([S_interior, t_interior])\n",
        "                loss, L1, L3 = self.compute_loss(model, S_interior, t_interior, S_terminal, t_terminal)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "            return loss, L1, L3\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            S_interior, t_interior, S_terminal, t_terminal = self.sampler.run(n_interior, n_terminal)\n",
        "            S_interior = tf.convert_to_tensor(S_interior, dtype=tf.float32)\n",
        "            t_interior = tf.convert_to_tensor(t_interior, dtype=tf.float32)\n",
        "            S_terminal = tf.convert_to_tensor(S_terminal, dtype=tf.float32)\n",
        "            t_terminal = tf.convert_to_tensor(t_terminal, dtype=tf.float32)\n",
        "\n",
        "            for _ in range(steps_per_sample):\n",
        "                loss, L1, L3 = train_step(S_interior, t_interior, S_terminal, t_terminal)\n",
        "\n",
        "            self.loss_vec.append(loss.numpy())\n",
        "            self.L1_vec.append(L1.numpy())\n",
        "            self.L3_vec.append(L3.numpy())\n",
        "\n",
        "            if i % 10 == 0:\n",
        "              print(f\"Iteration {i}: Loss: {loss.numpy()}; L1: {L1.numpy()}; L3: {L3.numpy()}\")\n",
        "\n",
        "            if loss.numpy() < 0.01:\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if self.dim == 1:\n",
        "            self.plot_CEV(self.model)\n",
        "\n",
        "\n",
        "\n",
        "        plt.plot(np.log(self.loss_vec))\n",
        "        plt.xlabel('Sampling Stage')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss over Time')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        S02 = np.full((1, self.dim), 50, dtype=np.float32)\n",
        "        S03 = np.full((1, self.dim), 55, dtype=np.float32)\n",
        "        S04 = np.full((1, self.dim), 60, dtype=np.float32)\n",
        "        S01 = np.full((1, self.dim), 45, dtype=np.float32)\n",
        "\n",
        "        t0 = np.array([[0]])  # Time to maturity\n",
        "        value_at_S01 = model(S01, t0).numpy()\n",
        "        value_at_S02 = model(S02, t0).numpy()\n",
        "        value_at_S03 = model(S03, t0).numpy()\n",
        "        value_at_S04 = model(S04, t0).numpy()\n",
        "\n",
        "        print(\"Option Value at S0 = 45 for all assets:\", value_at_S01)\n",
        "        print(\"Option Value at S0 = 50 for all assets:\", value_at_S02)\n",
        "        print(\"Option Value at S0 = 55 for all assets:\", value_at_S03)\n",
        "        print(\"Option Value at S0 = 60 for all assets:\", value_at_S04)\n",
        "\n",
        "    def trainAgain(self, saved_name, n_samples, steps_per_sample, n_layers=3, layer_width=50, n_interior=32, n_boundary=32, n_terminal=32):\n",
        "\n",
        "        self.model = DGMNet(n_layers, layer_width, input_dim=self.dim)\n",
        "\n",
        "        self.model_path = os.path.join(DIR_LOC, \"saved_models\", saved_name, saved_name + \".ckpt\")\n",
        "        self.model.load_weights(self.model_path)\n",
        "\n",
        "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-2, decay_steps=1000, decay_rate=0.9)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "        self.loss_vec, self.L1_vec, self.L3_vec = [], [], []\n",
        "\n",
        "        @tf.function\n",
        "        def train_step(S_interior, t_interior, S_terminal, t_terminal):\n",
        "            with tf.GradientTape(persistent=True) as tape:\n",
        "                tape.watch([S_interior, t_interior])\n",
        "                loss, L1, L3 = self.compute_loss(self.model, S_interior, t_interior, S_terminal, t_terminal)\n",
        "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
        "            return loss, L1, L3\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            S_interior, t_interior, S_terminal, t_terminal = self.sampler.run(n_interior, n_terminal)\n",
        "            S_interior = tf.convert_to_tensor(S_interior, dtype=tf.float32)\n",
        "            t_interior = tf.convert_to_tensor(t_interior, dtype=tf.float32)\n",
        "            S_terminal = tf.convert_to_tensor(S_terminal, dtype=tf.float32)\n",
        "            t_terminal = tf.convert_to_tensor(t_terminal, dtype=tf.float32)\n",
        "\n",
        "            for _ in range(steps_per_sample):\n",
        "                loss, L1, L3 = train_step(S_interior, t_interior, S_terminal, t_terminal)\n",
        "\n",
        "            self.loss_vec.append(loss.numpy())\n",
        "            self.L1_vec.append(L1.numpy())\n",
        "            self.L3_vec.append(L3.numpy())\n",
        "\n",
        "            print(f\"Iteration {i}: Loss: {loss.numpy()}; L1: {L1.numpy()}; L3: {L3.numpy()}\")\n",
        "\n",
        "            if loss.numpy() < 0.02:\n",
        "                break\n",
        "\n",
        "        #if self.dim == 1:\n",
        "            #self.plot_results(self.model)\n",
        "\n",
        "        #if self.dim == 0:\n",
        "            #self.checkExchange(self.model)\n",
        "\n",
        "        epochs = range(1, len(self.loss_vec) + 1)\n",
        "        plt.plot(epochs, self.loss_vec)\n",
        "        plt.yscale('log')  # Set y-axis to logarithmic scale\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    def restore(self, S, t, saved_name, n_layers=3, layer_width=50):\n",
        "        self.model = DGMNet(n_layers, layer_width, input_dim=self.dim)\n",
        "        sample_S = tf.zeros((1000, self.dim))\n",
        "        sample_t = tf.ones(sample_S.shape)  # Replace with appropriate shapes\n",
        "        _ = self.model(sample_S, sample_t)\n",
        "        model_path = os.path.join(DIR_LOC, \"saved_models\", saved_name, saved_name + \".ckpt\")\n",
        "        self.model.load_weights(model_path)\n",
        "        # Prepare input tensors\n",
        "        S_interior_tnsr = tf.convert_to_tensor(S, dtype=tf.float64)\n",
        "        t_interior_tnsr = tf.convert_to_tensor(t, dtype=tf.float64)\n",
        "\n",
        "        # Predict using the loaded model\n",
        "        fitted_optionValue = self.model(S_interior_tnsr, t_interior_tnsr)\n",
        "\n",
        "        print(\"Model {}: {}\".format(saved_name, fitted_optionValue.numpy().T))\n",
        "        return fitted_optionValue.numpy().T\n",
        "\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, model, S_interior, t_interior, S_terminal, t_terminal):\n",
        "        S_interior = tf.convert_to_tensor(S_interior, dtype=tf.float32)\n",
        "        t_interior = tf.convert_to_tensor(t_interior, dtype=tf.float32)\n",
        "        S_terminal = tf.convert_to_tensor(S_terminal, dtype=tf.float32)\n",
        "        t_terminal = tf.convert_to_tensor(t_terminal, dtype=tf.float32)\n",
        "\n",
        "\n",
        "        with tf.GradientTape() as tape1:\n",
        "            tape1.watch([S_interior, t_interior])\n",
        "            with tf.GradientTape() as tape2:\n",
        "                tape2.watch([S_interior, t_interior])\n",
        "                V = model(S_interior, t_interior)\n",
        "            V_s = tape2.gradient(V, S_interior)\n",
        "        V_ss = tape1.batch_jacobian(V_s, S_interior)\n",
        "\n",
        "\n",
        "\n",
        "        with tf.GradientTape() as tape3:\n",
        "            tape3.watch([S_interior, t_interior])\n",
        "            V = model(S_interior, t_interior)\n",
        "        V_t = tape3.gradient(V, t_interior)\n",
        "\n",
        "        S_interiorbeta = tf.pow(S_interior, self.beta)\n",
        "        sec_ord = 0\n",
        "        for i in range(self.dim):\n",
        "            for j in range(self.dim):\n",
        "                S_coli = tf.reshape(S_interiorbeta[:, i], [-1, 1])\n",
        "                S_colj = tf.reshape(S_interiorbeta[:, j], [-1, 1])\n",
        "                V_ss_column = tf.reshape(V_ss[:, i, j], [-1, 1])\n",
        "                sec_ord += self.vol_vec[i] * self.vol_vec[j] * self.corr_mat[i, j] * S_coli * S_colj * V_ss_column\n",
        "\n",
        "        fir_ord = 0\n",
        "        for i in range(self.dim):\n",
        "            V_s_column = tf.reshape(V_s[:, i], [-1, 1])\n",
        "            S_col1 = tf.reshape(S_interior[:, i], [-1, 1])\n",
        "            fir_ord += (self.ir - self.dividend_vec[i]) * S_col1 * V_s_column\n",
        "\n",
        "\n",
        "\n",
        "        diff_V = V_t + 0.5 * sec_ord + fir_ord - self.ir * V\n",
        "\n",
        "        L1 = tf.reduce_mean(tf.square(diff_V))\n",
        "\n",
        "        # Payoff evaluation at terminal time\n",
        "        target_payoff = tf.convert_to_tensor(self.payoff_func(S_terminal), dtype=tf.float32)\n",
        "        fitted_payoff = tf.reshape(model(S_terminal, t_terminal), [-1])\n",
        "        L3 = tf.reduce_mean(tf.square(fitted_payoff - target_payoff))\n",
        "\n",
        "\n",
        "        # Combining all components of the loss function\n",
        "        total_loss = L1 + L3\n",
        "\n",
        "\n",
        "        return total_loss, L1, L3\n",
        "\n",
        "    def plot_CEV(self, model):\n",
        "        S_plot = np.linspace(self.domain.lower_bound, self.domain.upper_bound, 100).reshape(-1, 1)\n",
        "        t_plot = np.full(S_plot.shape, self.domain.T)\n",
        "        plt.figure()\n",
        "        plt.figure(figsize = (12,10))\n",
        "\n",
        "        optionValue = CEVclosed(S_plot, self.strike, self.ir, self.dividend_vec[0], 0.5, self.vol_vec[0], 1.0)\n",
        "\n",
        "\n",
        "        #BS, _ = BSM(S_plot, self.strike, self.ir, self.vol_vec[0], 0, self.dividend_vec[0])\n",
        "        # compute normalized density at all x values to plot and current t value\n",
        "        t_plot = np.full(S_plot.shape, 0, dtype=np.float32)\n",
        "        value = model(S_plot, t_plot).numpy()\n",
        "\n",
        "        # plot histogram of simulated process values and overlay estimated density\n",
        "        plt.plot(S_plot, optionValue, color = 'b', label='Analytical Solution', linewidth = 3, linestyle=':')\n",
        "        plt.plot(S_plot, value, color = 'r', label='Network estimate')\n",
        "        #plt.plot(S_plot, BS, color = 'g', label='Black-Scholes Solution', linewidth = 3, linestyle=':')\n",
        "\n",
        "\n",
        "        # subplot options\n",
        "\n",
        "        plt.xlabel(\"Spot Price\", fontsize=20, labelpad=10)\n",
        "        plt.ylabel(\"Option Price\", fontsize=20, labelpad=20)\n",
        "\n",
        "        plt.xticks(fontsize=13)\n",
        "        plt.yticks(fontsize=13)\n",
        "        plt.grid(linestyle=':')\n",
        "\n",
        "\n",
        "        plt.legend(loc='upper left', prop={'size': 16})\n",
        "        # adjust space between subplots\n",
        "        # plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
        "\n",
        "        error = np.abs(value - optionValue)\n",
        "        #error = np.abs(value - BS)\n",
        "\n",
        "        total_error = np.sum(error)\n",
        "        print(\"Total Error at t = {}: {}\".format(0, total_error))\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        plt.figure()\n",
        "        plt.figure(figsize = (12,10))\n",
        "\n",
        "        #plt.subplot(2,2,i+1)\n",
        "        plt.plot(S_plot, error)\n",
        "        plt.ylim(0, 0.5)\n",
        "        plt.xlabel(\"Spot Price\", fontsize = 20)\n",
        "        plt.ylabel(\"Absolute Error\", fontsize = 20)\n",
        "        plt.title(\"Absolute Error\", fontsize = 20)\n",
        "        #plt.text(0.5, 0.9, f'Total Error: {total_error:.4f}', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0HEskY9E_PS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class EuroHeston:\n",
        "    def __init__(self, payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, strike, kappa, theta, xi, rho, sampler=None):\n",
        "        self.payoff_func = payoff_func\n",
        "        self.domain = domain\n",
        "        self.dim = domain.dim\n",
        "        self.vol_vec = vol_vec\n",
        "        self.ir = ir\n",
        "        self.dividend_vec = dividend_vec\n",
        "        self.corr_mat = corr_mat\n",
        "        self.strike = strike\n",
        "        self.kappa = kappa\n",
        "        self.theta = theta\n",
        "        self.xi = xi\n",
        "        self.rho = rho\n",
        "        self.sampler = sampler if sampler is not None else SamplerHeston(domain, vol_vec[0], kappa, theta, xi, rho)\n",
        "        self.model = None\n",
        "\n",
        "    def run(self, n_samples, steps_per_sample, n_layers=3, layer_width=50, n_interior=16,\n",
        "            n_boundary=16, n_terminal=32, saved_name=None, new_training=True):\n",
        "        if new_training:\n",
        "            if not saved_name:\n",
        "                pickle_dir = DIR_LOC+\"/saved_models/{}_Euro\".format(time.strftime(\"%Y%m%d\"))\n",
        "                saved_name = \"{}_Euro.ckpt\".format(time.strftime(\"%Y%m%d\"))\n",
        "            else:\n",
        "                pickle_dir = DIR_LOC+\"/saved_models/{}_{}\".format(time.strftime(\"%Y%m%d\"), saved_name)\n",
        "                saved_name = time.strftime(\"%Y%m%d\") + \"_\" + saved_name + \".ckpt\"\n",
        "\n",
        "            if not os.path.exists(pickle_dir):\n",
        "                os.makedirs(pickle_dir)\n",
        "\n",
        "        model = DGMNet(n_layers, layer_width, input_dim=self.dim + 1)  # Additional dimension for variance\n",
        "        self.model = model\n",
        "\n",
        "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-2, decay_steps=1000, decay_rate=0.9)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.005)\n",
        "\n",
        "        self.loss_vec, self.L1_vec, self.L3_vec = [], [], []\n",
        "\n",
        "        @tf.function\n",
        "        def train_step(S_interior, V_interior, t_interior, S_terminal, V_terminal, t_terminal):\n",
        "            with tf.GradientTape(persistent=True) as tape:\n",
        "                tape.watch([S_interior, V_interior, t_interior])\n",
        "                loss, L1, L3 = self.compute_loss(model, S_interior, V_interior, t_interior, S_terminal, V_terminal, t_terminal)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "            return loss, L1, L3\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            S_interior, V_interior, t_interior, S_terminal, V_terminal, t_terminal = self.sampler.run(n_interior, n_terminal)\n",
        "            S_interior = tf.convert_to_tensor(S_interior, dtype=tf.float32)\n",
        "            V_interior = tf.convert_to_tensor(V_interior, dtype=tf.float32)\n",
        "            t_interior = tf.convert_to_tensor(t_interior, dtype=tf.float32)\n",
        "            S_terminal = tf.convert_to_tensor(S_terminal, dtype=tf.float32)\n",
        "            V_terminal = tf.convert_to_tensor(V_terminal, dtype=tf.float32)\n",
        "            t_terminal = tf.convert_to_tensor(t_terminal, dtype=tf.float32)\n",
        "\n",
        "            for _ in range(steps_per_sample):\n",
        "                loss, L1, L3 = train_step(S_interior, V_interior, t_interior, S_terminal, V_terminal, t_terminal)\n",
        "\n",
        "            self.loss_vec.append(loss.numpy())\n",
        "            self.L1_vec.append(L1.numpy())\n",
        "            self.L3_vec.append(L3.numpy())\n",
        "\n",
        "            print(f\"Iteration {i}: Loss: {loss.numpy()}; L1: {L1.numpy()}; L3: {L3.numpy()}\")\n",
        "\n",
        "            # if loss.numpy() < 0.1:\n",
        "            #     break\n",
        "\n",
        "        self.plot_option_value(model)\n",
        "\n",
        "\n",
        "        if new_training:\n",
        "            self.model.save_weights(saved_name)\n",
        "\n",
        "            with open(pickle_dir + \"_lossvec.pickle\", 'wb') as f:\n",
        "                pickle.dump(self.loss_vec, f)\n",
        "            with open(pickle_dir + \"_l1vec.pickle\", 'wb') as f:\n",
        "                pickle.dump(self.L1_vec, f)\n",
        "\n",
        "            with open(pickle_dir + \"_l3vec.pickle\", 'wb') as f:\n",
        "                pickle.dump(self.L3_vec, f)\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, model, S_interior, V_interior, t_interior, S_terminal, V_terminal, t_terminal):\n",
        "        S_interior = tf.convert_to_tensor(S_interior, dtype=tf.float32)\n",
        "        V_interior = tf.convert_to_tensor(V_interior, dtype=tf.float32)\n",
        "        t_interior = tf.convert_to_tensor(t_interior, dtype=tf.float32)\n",
        "        S_terminal = tf.convert_to_tensor(S_terminal, dtype=tf.float32)\n",
        "        V_terminal = tf.convert_to_tensor(V_terminal, dtype=tf.float32)\n",
        "        t_terminal = tf.convert_to_tensor(t_terminal, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            tape.watch([S_interior, V_interior, t_interior])\n",
        "            V = model(tf.concat([S_interior, V_interior], axis=1), t_interior)\n",
        "            V_s = tape.gradient(V, S_interior)\n",
        "            V_v = tape.gradient(V, V_interior)\n",
        "\n",
        "        V_ss = tape.gradient(V_s, S_interior)\n",
        "        V_vv = tape.gradient(V_v, V_interior)\n",
        "        V_sv = tape.gradient(V_s, V_interior)\n",
        "        V_t = tape.gradient(V, t_interior)\n",
        "\n",
        "\n",
        "        sec_ord = 0.5 * (S_interior**2 * V_interior * V_ss + self.xi**2 * V_interior * V_vv + 2 * self.rho * self.xi * S_interior * V_interior * V_sv)\n",
        "        first_ord = (self.ir - self.dividend_vec) * S_interior * V_s + self.kappa * (self.theta - V_interior) * V_v\n",
        "        diff_V = V_t + sec_ord + first_ord - self.ir * V\n",
        "        L1 = tf.reduce_mean(tf.square(diff_V))\n",
        "\n",
        "        target_payoff = tf.convert_to_tensor(self.payoff_func(S_terminal), dtype=tf.float32)\n",
        "        fitted_payoff = tf.reshape(model(tf.concat([S_terminal, V_terminal], axis=1), t_terminal), [-1])\n",
        "        L3 = tf.reduce_mean(tf.square(fitted_payoff - target_payoff))\n",
        "\n",
        "        return L1 + L3, L1, L3\n",
        "\n",
        "    def plot_training_loss(self):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(self.loss_vec, label='Total Loss')\n",
        "        plt.plot(self.L1_vec, label='L1 Loss (PDE Residual)')\n",
        "        plt.plot(self.L3_vec, label='L3 Loss (Payoff)')\n",
        "        plt.xlabel('Iteration')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss Over Time')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_option_value(self, model):\n",
        "        S_plot = np.linspace(self.domain.lower_bound, self.domain.upper_bound, 100).reshape(-1, 1)\n",
        "        V_plot = np.linspace(0, 1, 100).reshape(-1, 1)\n",
        "        plt.figure()\n",
        "        plt.figure(figsize = (12,10))\n",
        "        error = []\n",
        "        total_error = []\n",
        "        # time values at which to examine density\n",
        "        valueTimes = [0, 1/3, 2/3, 1]\n",
        "        for i, curr_t in enumerate(valueTimes):\n",
        "\n",
        "            S = np.c_[S_plot, np.full(S_plot.shape, 0.15)]\n",
        "           #S = np.c_[S_plot, V_plot]\n",
        "            t_vals = np.full((S.shape[0], 1), curr_t)\n",
        "\n",
        "            # specify subplot\n",
        "            plt.subplot(2,2,i+1)\n",
        "\n",
        "            if curr_t == 1:\n",
        "                prices = [heston_call_price(S0, self.strike, 0.01, self.ir, self.dividend_vec[0], self.vol_vec[0], self.kappa, self.theta, self.xi, self.rho) for S0 in S_plot]\n",
        "            else:\n",
        "                prices = [heston_call_price(S0, self.strike, self.domain.T - curr_t, self.ir, self.dividend_vec[0], self.vol_vec[0], self.kappa, self.theta, self.xi, self.rho) for S0 in S_plot]\n",
        "            prices = np.nan_to_num(prices).flatten()\n",
        "\n",
        "            # simulate process at current t\n",
        "\n",
        "\n",
        "\n",
        "            # compute normalized density at all x values to plot and current t value\n",
        "            t_plot = np.full(S_plot.shape, curr_t, dtype=np.float32)\n",
        "            value = model(S, t_vals).numpy().flatten()\n",
        "\n",
        "            # plot histogram of simulated process values and overlay estimated density\n",
        "            plt.plot(S_plot, prices, color = 'b', label='Analytical Solution', linewidth = 3, linestyle=':')\n",
        "            plt.plot(S_plot, value, color = 'r', label='Network estimate')\n",
        "\n",
        "\n",
        "            # subplot options\n",
        "\n",
        "            plt.xlabel(\"Spot Price\", fontsize=15, labelpad=10)\n",
        "            plt.ylabel(\"Option Price\", fontsize=15, labelpad=20)\n",
        "\n",
        "            plt.xticks(fontsize=13)\n",
        "            plt.yticks(fontsize=13)\n",
        "            plt.grid(linestyle=':')\n",
        "\n",
        "            if i == 0:\n",
        "                plt.legend(loc='upper left', prop={'size': 16})\n",
        "            # adjust space between subplots\n",
        "            plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
        "\n",
        "            error.append(np.abs(value - prices))\n",
        "\n",
        "            total_error.append(np.sum(error[i]))\n",
        "            print(\"Total Error at t = {}: {}\".format(curr_t, total_error[i]))\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure()\n",
        "        plt.figure(figsize = (12,10))\n",
        "        for i in range(len(valueTimes)):\n",
        "            plt.subplot(2,2,i+1)\n",
        "            plt.plot(S_plot, error[i])\n",
        "\n",
        "            plt.xlabel(\"Spot Price\")\n",
        "            plt.ylabel(\"Absolute Error\")\n",
        "            plt.title(\"Absolute Error\")\n",
        "            #plt.text(0.5, 0.9, f'Total Error: {total_error[i]:.4f}', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVVqTKFHkYxq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import qmc\n",
        "\n",
        "class SobolSamplerHeston:\n",
        "    def __init__(self, domainNd, v0, kappa, theta, xi, rho):\n",
        "        self.domain = domainNd\n",
        "        self.v0 = v0  # Initial variance\n",
        "        self.kappa = kappa\n",
        "        self.theta = theta\n",
        "        self.xi = xi\n",
        "        self.rho = rho\n",
        "\n",
        "    def run(self, n_interior, n_terminal):\n",
        "        dim, T = self.domain.dim, self.domain.T\n",
        "        lower_bound, upper_bound = self.domain.lower_bound, self.domain.upper_bound * 1.3\n",
        "\n",
        "        # Sobol sequence sampler\n",
        "        sampler_interior = qmc.Sobol(d=dim + 1)\n",
        "        sampler_terminal = qmc.Sobol(d=dim + 1)\n",
        "\n",
        "        # Generate Sobol sequence for interior and terminal times and asset prices\n",
        "        sobol_interior = sampler_interior.random(n=n_interior)\n",
        "        sobol_terminal = sampler_terminal.random(n=n_terminal)\n",
        "\n",
        "        # Map Sobol sequence to the desired ranges\n",
        "        t_interior = T * sobol_interior[:, 0].reshape(-1, 1)\n",
        "        S_interior = lower_bound + (upper_bound - lower_bound) * sobol_interior[:, 1:]\n",
        "\n",
        "        t_terminal = T * np.ones((n_terminal, 1))\n",
        "        S_terminal = lower_bound + (upper_bound - lower_bound) * sobol_terminal[:, 1:]\n",
        "\n",
        "        # Sample variances\n",
        "        V_interior = self.sample_variance(n_interior)\n",
        "        V_terminal = self.sample_variance(n_terminal)\n",
        "\n",
        "        return S_interior, V_interior, t_interior, S_terminal, V_terminal, t_terminal\n",
        "\n",
        "    def sample_variance(self, n_samples):\n",
        "        # Sobol sequence for variances\n",
        "        sampler_variance = qmc.Sobol(d=1)\n",
        "        sobol_variance = sampler_variance.random(n=n_samples)\n",
        "\n",
        "        # Sample variances according to the Heston model dynamics\n",
        "        variances = self.theta + (self.v0 - self.theta) * np.exp(-self.kappa * sobol_variance[:, 0]) \\\n",
        "                    + self.xi * np.sqrt((1 - np.exp(-2 * self.kappa * sobol_variance[:, 0])) / (2 * self.kappa))\n",
        "        return np.maximum(variances, 0).reshape(-1, 1)  # Ensure non-negative variances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBgdbsJk1I4P"
      },
      "outputs": [],
      "source": [
        "import sys, os, time\n",
        "DIR_LOC = os.getcwd()\n",
        "sys.path.append(DIR_LOC+\"/..\")\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.ticker import LogFormatter\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "class Euro:\n",
        "    def __init__(self, payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, strike, multi, sampler=None):\n",
        "        self.payoff_func = payoff_func\n",
        "        self.domain = domain\n",
        "        self.dim = domain.dim\n",
        "        self.vol_vec = vol_vec\n",
        "        self.ir = ir\n",
        "        self.dividend_vec = dividend_vec\n",
        "        self.corr_mat = corr_mat\n",
        "        self.strike = strike\n",
        "        self.multi = multi\n",
        "        self.cov_mat = np.outer(vol_vec, vol_vec) * corr_mat\n",
        "        self.sampler = sampler if sampler is not None else SamplerNdV2(domain, multi)\n",
        "        self.model = None\n",
        "\n",
        "    def run(self, n_samples, steps_per_sample, n_layers=3, layer_width=50, n_interior=16,\n",
        "            n_boundary=16, n_terminal=32, saved_name = None, new_training = False):\n",
        "\n",
        "        if new_training:\n",
        "            if not saved_name:\n",
        "                pickle_dir = DIR_LOC+\"/saved_models/{}_Euro\".format(time.strftime(\"%Y%m%d\"))\n",
        "                saved_name = \"{}_Euro.ckpt\".format(time.strftime(\"%Y%m%d\"))\n",
        "            else:\n",
        "                pickle_dir = DIR_LOC+\"/saved_models/{}_{}\".format(time.strftime(\"%Y%m%d\"), saved_name)\n",
        "                saved_name = saved_name + \".weights.h5\"\n",
        "\n",
        "            if not os.path.exists(pickle_dir):\n",
        "                os.makedirs(pickle_dir)\n",
        "\n",
        "\n",
        "        model = DGMNet(n_layers, layer_width, input_dim=self.dim)\n",
        "        self.model = model\n",
        "\n",
        "        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-2, decay_steps=1000, decay_rate=0.9)\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001)\n",
        "\n",
        "        self.loss_vec, self.L1_vec, self.L2_vec, self.L3_vec = [], [], [], []\n",
        "\n",
        "        @tf.function\n",
        "        def train_step(S_interior, t_interior, S_terminal, t_terminal, S_boundary_zero, t_boundary_zero, S_boundary_infinity, t_boundary_infinity):\n",
        "            with tf.GradientTape(persistent=True) as tape:\n",
        "                tape.watch([S_interior, t_interior, S_terminal, t_terminal, S_boundary_zero, t_boundary_zero, S_boundary_infinity, t_boundary_infinity])\n",
        "                loss, L1, L2, L3 = self.compute_loss(model, S_interior, t_interior, S_terminal, t_terminal, S_boundary_zero, t_boundary_zero, S_boundary_infinity, t_boundary_infinity)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "            return loss, L1, L2, L3\n",
        "\n",
        "        cumulative_time = 0.0\n",
        "        for i in range(n_samples):\n",
        "        # Sample points including boundary conditions\n",
        "            S_interior, t_interior, S_terminal, t_terminal, S_boundary_zero, t_boundary_zero, S_boundary_infinity, t_boundary_infinity = self.sampler.run(n_interior, n_terminal, n_boundary)\n",
        "            S_interior = tf.convert_to_tensor(S_interior, dtype=tf.float32)\n",
        "            t_interior = tf.convert_to_tensor(t_interior, dtype=tf.float32)\n",
        "            S_boundary_zero = tf.convert_to_tensor(S_boundary_zero, dtype=tf.float32)\n",
        "            t_boundary_zero = tf.convert_to_tensor(t_boundary_zero, dtype=tf.float32)\n",
        "            S_boundary_infinity = tf.convert_to_tensor(S_boundary_infinity, dtype=tf.float32)\n",
        "            t_boundary_infinity = tf.convert_to_tensor(t_boundary_infinity, dtype=tf.float32)\n",
        "            S_terminal = tf.convert_to_tensor(S_terminal, dtype=tf.float32)\n",
        "            t_terminal = tf.convert_to_tensor(t_terminal, dtype=tf.float32)\n",
        "\n",
        "            for _ in range(steps_per_sample):\n",
        "                loss, L1, L2, L3 = train_step(S_interior, t_interior, S_terminal, t_terminal, S_boundary_zero, t_boundary_zero, S_boundary_infinity, t_boundary_infinity)\n",
        "\n",
        "            self.loss_vec.append(loss.numpy())\n",
        "            self.L1_vec.append(L1.numpy())\n",
        "            self.L2_vec.append(L2.numpy())\n",
        "            self.L3_vec.append(L3.numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Iteration {i}: Loss: {loss.numpy()}; L1: {L1.numpy()}; L2: {L2.numpy()}; L3: {L3.numpy()}\")\n",
        "            if loss.numpy() < 0.1:\n",
        "                break\n",
        "\n",
        "\n",
        "        if new_training:\n",
        "            self.model.save_weights(saved_name)\n",
        "\n",
        "            with open(pickle_dir + \"_lossvec.pickle\", 'wb') as f:\n",
        "                pickle.dump(self.loss_vec, f)\n",
        "            with open(pickle_dir + \"_l1vec.pickle\", 'wb') as f:\n",
        "                pickle.dump(self.L1_vec, f)\n",
        "\n",
        "            with open(pickle_dir + \"_l3vec.pickle\", 'wb') as f:\n",
        "                pickle.dump(self.L3_vec, f)\n",
        "\n",
        "        S03 = np.full((1, self.dim), 50, dtype=np.float32)\n",
        "        S04 = np.full((1, self.dim), 55, dtype=np.float32)\n",
        "        S05 = np.full((1, self.dim), 60, dtype=np.float32)\n",
        "        S02 = np.full((1, self.dim), 45, dtype=np.float32)\n",
        "        S01 = np.full((1, self.dim), 40, dtype=np.float32)\n",
        "        t0 = np.array([[0]])  # Time to maturity\n",
        "        value_at_S01 = model(S01, t0).numpy()\n",
        "        value_at_S02 = model(S02, t0).numpy()\n",
        "        value_at_S03 = model(S03, t0).numpy()\n",
        "        value_at_S04 = model(S04, t0).numpy()\n",
        "        value_at_S05 = model(S05, t0).numpy()\n",
        "        print(\"Option Value at S0 = 40 for all assets:\", value_at_S01)\n",
        "        print(\"Option Value at S0 = 45 for all assets:\", value_at_S02)\n",
        "        print(\"Option Value at S0 = 50 for all assets:\", value_at_S03)\n",
        "        print(\"Option Value at S0 = 55 for all assets:\", value_at_S04)\n",
        "        print(\"Option Value at S0 = 60 for all assets:\", value_at_S05)\n",
        "\n",
        "        if self.dim == 1:\n",
        "            self.plot_results(self.model)\n",
        "\n",
        "        if self.dim == 2:\n",
        "            self.checkExchange(model)\n",
        "\n",
        "        # Custom formatter function\n",
        "        def log_formatter(y, pos):\n",
        "            exponent = int(np.log10(y))\n",
        "            return f'$10^{{{exponent}}}$'\n",
        "\n",
        "        # Create a range of epochs based on the length of self.loss_vec\n",
        "        epochs = range(1, len(self.loss_vec) + 1)\n",
        "\n",
        "        # Plot the loss values\n",
        "        plt.plot(epochs, self.loss_vec)\n",
        "\n",
        "        # Set y-axis to logarithmic scale\n",
        "        plt.yscale('log')\n",
        "\n",
        "        # Use a custom formatter for the y-axis\n",
        "        formatter = FuncFormatter(log_formatter)\n",
        "        plt.gca().yaxis.set_major_formatter(formatter)\n",
        "\n",
        "        # Set labels and title\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Training Loss')\n",
        "\n",
        "        # Display the plot\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    @tf.function\n",
        "    def compute_loss(self, model, S_interior, t_interior, S_terminal, t_terminal, S_boundary_zero, t_boundary_zero, S_boundary_infinity, t_boundary_infinity):\n",
        "        S_interior = tf.convert_to_tensor(S_interior, dtype=tf.float32)\n",
        "        t_interior = tf.convert_to_tensor(t_interior, dtype=tf.float32)\n",
        "        S_terminal = tf.convert_to_tensor(S_terminal, dtype=tf.float32)\n",
        "        t_terminal = tf.convert_to_tensor(t_terminal, dtype=tf.float32)\n",
        "\n",
        "        with tf.GradientTape() as tape1:\n",
        "            tape1.watch([S_interior, t_interior])\n",
        "            with tf.GradientTape() as tape2:\n",
        "                tape2.watch([S_interior, t_interior])\n",
        "                V = model(S_interior, t_interior)\n",
        "            V_s = tape2.gradient(V, S_interior)\n",
        "        V_ss = tape1.batch_jacobian(V_s, S_interior)\n",
        "\n",
        "\n",
        "\n",
        "        with tf.GradientTape() as tape3:\n",
        "            tape3.watch([S_interior, t_interior])\n",
        "            V = model(S_interior, t_interior)\n",
        "        V_t = tape3.gradient(V, t_interior)\n",
        "\n",
        "        sec_ord = 0\n",
        "        for i in range(self.dim):\n",
        "            for j in range(self.dim):\n",
        "                S_coli = tf.reshape(S_interior[:, i], [-1, 1])\n",
        "                S_colj = tf.reshape(S_interior[:, j], [-1, 1])\n",
        "                V_ss_column = tf.reshape(V_ss[:, i, j], [-1, 1])\n",
        "                sec_ord += self.vol_vec[i] * self.vol_vec[j] * self.corr_mat[i, j] * S_coli * S_colj * V_ss_column\n",
        "\n",
        "        fir_ord = 0\n",
        "        for i in range(self.dim):\n",
        "            V_s_column = tf.reshape(V_s[:, i], [-1, 1])\n",
        "            S_col1 = tf.reshape(S_interior[:, i], [-1, 1])\n",
        "            fir_ord += (self.ir - self.dividend_vec[i]) * S_col1 * V_s_column\n",
        "\n",
        "\n",
        "\n",
        "        diff_V = V_t + 0.5 * sec_ord + fir_ord - self.ir * V\n",
        "\n",
        "        L1 = tf.reduce_mean(tf.square(diff_V))\n",
        "\n",
        "        # Boundary Condition 1: C(t, 0) = 0\n",
        "        V_boundary_zero = model(S_boundary_zero, t_boundary_zero)\n",
        "        L_boundary_zero = tf.reduce_mean(tf.square(V_boundary_zero))\n",
        "\n",
        "        # # Boundary Condition 2: C(t, S)  S as S  \n",
        "        # V_boundary_infinity = model(S_boundary_infinity, t_boundary_infinity)\n",
        "        # L_boundary_infinity = tf.reduce_mean(tf.square(V_boundary_infinity - S_boundary_infinity))\n",
        "\n",
        "\n",
        "        L2 = L_boundary_zero\n",
        "        # Payoff evaluation at terminal time\n",
        "        target_payoff = tf.convert_to_tensor(self.payoff_func(S_terminal), dtype=tf.float32)\n",
        "        fitted_payoff = tf.reshape(model(S_terminal, t_terminal), [-1])\n",
        "        L3 = tf.reduce_mean(tf.square(fitted_payoff - target_payoff))\n",
        "\n",
        "\n",
        "        # Combining all components of the loss function\n",
        "        total_loss = L1 + L2 + L3\n",
        "\n",
        "\n",
        "        return total_loss, L1, L2, L3\n",
        "\n",
        "    def plot_results(self, model):\n",
        "        S_plot = np.linspace(self.domain.lower_bound, self.domain.upper_bound, 100).reshape(-1, 1)\n",
        "        plt.figure()\n",
        "        plt.figure(figsize = (12,10))\n",
        "        error = []\n",
        "        total_error = []\n",
        "        # time values at which to examine density\n",
        "        valueTimes = [0, 1/3, 2*1/3, 1]\n",
        "        for i, curr_t in enumerate(valueTimes):\n",
        "\n",
        "            # specify subplot\n",
        "            plt.subplot(2,2,i+1)\n",
        "\n",
        "            # simulate process at current t\n",
        "            optionValue, _ =  BSM(S_plot, self.strike, self.ir, self.vol_vec[0], curr_t, self.dividend_vec[0])\n",
        "\n",
        "            # compute normalized density at all x values to plot and current t value\n",
        "            t_plot = np.full(S_plot.shape, curr_t, dtype=np.float32)\n",
        "            value = model(S_plot, t_plot).numpy()\n",
        "\n",
        "            # plot histogram of simulated process values and overlay estimated density\n",
        "            plt.plot(S_plot, optionValue, color = 'b', label='Analytical Solution', linewidth = 3, linestyle=':')\n",
        "            plt.plot(S_plot, value, color = 'r', label='Network Estimate')\n",
        "\n",
        "\n",
        "            # subplot options\n",
        "\n",
        "            plt.xlabel(\"Spot Price\", fontsize=15, labelpad=10)\n",
        "            plt.ylabel(\"Option Price\", fontsize=15, labelpad=20)\n",
        "            #plt.title(\"t = \" + str(curr_t), fontsize=18, y=1.03)\n",
        "            plt.xticks(fontsize=13)\n",
        "            plt.yticks(fontsize=13)\n",
        "            plt.grid(linestyle=':')\n",
        "\n",
        "            if i == 0:\n",
        "                plt.legend(loc='upper left', prop={'size': 16})\n",
        "            # adjust space between subplots\n",
        "            plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
        "\n",
        "            error.append(np.abs(value - optionValue))\n",
        "\n",
        "            total_error.append(np.sum(error[i]))\n",
        "            print(\"Total Error at t = {}: {}\".format(curr_t, total_error[i]))\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "        plt.figure()\n",
        "        plt.figure(figsize = (12,10))\n",
        "        for i in range(len(valueTimes)):\n",
        "            plt.subplot(2,2,i+1)\n",
        "            plt.plot(S_plot, error[i])\n",
        "            plt.ylim(0, 0.5)\n",
        "            plt.xlabel(\"Spot Price\")\n",
        "            plt.ylabel(\"Absolute Error\")\n",
        "            plt.title(\"Absolute Error\")\n",
        "            #plt.text(0.5, 0.9, f'Total Error: {total_error[i]:.4f}', ha='center', va='center', transform=plt.gca().transAxes)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Total Error: {}\".format(total_error))\n",
        "\n",
        "\n",
        "    def checkExchange(self, model):\n",
        "        S1_range = np.linspace(self.domain.lower_bound, self.domain.upper_bound, 50)\n",
        "        S2_range = np.linspace(20, 80, 50)\n",
        "\n",
        "        S1, S2 = np.meshgrid(S1_range, S2_range)\n",
        "        S1_flat = S1.flatten()\n",
        "        S2_flat = S2.flatten()\n",
        "        S_combined = np.vstack((S1_flat, S2_flat)).T\n",
        "        t_value = 0\n",
        "        t_flat = np.full(S1_flat.shape, 0, dtype=np.float32)\n",
        "\n",
        "        optionValue = margrabe(S1_flat, S2_flat, self.vol_vec[0], self.vol_vec[1], self.corr_mat[0, 1], self.dividend_vec[0], self.dividend_vec[1], t_value)\n",
        "        value = model(S_combined, t_flat.reshape(-1, 1)).numpy()\n",
        "\n",
        "        optionValue = optionValue.reshape(S1.shape)\n",
        "        value = value.reshape(S1.shape)\n",
        "\n",
        "        fig = plt.figure(figsize=(14, 10))\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "        surf = ax.plot_surface(S1, S2, value, cmap='viridis', edgecolor='none', alpha=0.7)\n",
        "        ax.plot_wireframe(S1, S2, optionValue, color='r', linestyle=':', linewidth=1)\n",
        "\n",
        "        ax.view_init(elev=30, azim=220)\n",
        "        ax.set_xlabel('S1')\n",
        "        ax.set_ylabel('S2')\n",
        "        ax.set_zlabel('Option Value')\n",
        "\n",
        "        fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5, label='Option Value')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        error = np.abs(value - np.nan_to_num(optionValue))\n",
        "        total_error = np.sum(error)\n",
        "\n",
        "        print(\"Total Error:\", total_error)\n",
        "\n",
        "        fig_error = plt.figure(figsize=(14, 10))\n",
        "        error_surface = np.abs(value - np.nan_to_num(optionValue)).reshape(S1.shape)\n",
        "\n",
        "        ax_error = fig_error.add_subplot(111, projection='3d')  # Create subplots for error surfaces\n",
        "        surf_error = ax_error.plot_surface(S1, S2, error_surface, cmap='coolwarm', edgecolor='none', alpha=0.7)\n",
        "\n",
        "        ax_error.view_init(elev=30, azim=220)\n",
        "        ax_error.set_xlabel('S1')\n",
        "        ax_error.set_ylabel('S2')\n",
        "        ax_error.set_zlabel('Error Value')\n",
        "          # Set title for each subplot\n",
        "        fig_error.colorbar(surf_error, ax=ax_error, shrink=0.5, aspect=5, label='Error')\n",
        "\n",
        "        total_error = np.sum(error_surface)\n",
        "        print(\"Total Error:\", total_error)\n",
        "        #ax_error.text2D(0.6, 1, f'Total Error: {total_error:.4f}', ha='center', va='center', transform=ax_error.transAxes, fontsize = 14)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "MqYKVPnXB3sl",
        "outputId": "73d3ef87-88dd-496c-fad5-e0e39d33781d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "SobolSamplerNd.run() missing 1 required positional argument: 'n_boundary'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cdd2e6dbbf17>\u001b[0m in \u001b[0;36m<cell line: 106>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m \u001b[0mtest_American\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-cdd2e6dbbf17>\u001b[0m in \u001b[0;36mtest_American\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_diagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAmerican\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayoff_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvol_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdividend_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSobolSamplerNd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_interior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_terminal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_heston1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-42cf9a5111a9>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, n_samples, steps_per_sample, n_layers, layer_width, n_interior, n_boundary, n_terminal)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mS_interior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_interior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_terminal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_terminal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_interior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_terminal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mS_interior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_interior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mt_interior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_interior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: SobolSamplerNd.run() missing 1 required positional argument: 'n_boundary'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def test_euro10d():\n",
        "    dim = 10\n",
        "    T = 1.0\n",
        "    domain = DomainNd(np.tile(np.array([35, 70], dtype=np.float32), (dim, 1)), T)\n",
        "    vol_vec, ir, dividend_vec, strike = 0.15*np.ones(dim, dtype=np.float32), 0.04, 0.01*np.ones(dim, dtype=np.float32), 50\n",
        "    multi = 1\n",
        "    # payoff_func = lambda x: tf.nn.relu(tf.math.reduce_sum(x, axis=1) - strike)\n",
        "    payoff_func = lambda x: tf.nn.relu(tf.pow(tf.math.reduce_prod(x, axis=1), 1/dim) - strike)\n",
        "    #payoff_func = lambda x: tf.nn.relu(tf.reduce_max(x, axis=1) - strike)\n",
        "\n",
        "    corr_mat = 0.25 * np.ones((dim, dim), dtype=np.float32)\n",
        "    np.fill_diagonal(corr_mat, 1.0)\n",
        "    solver = Euro(payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, strike, multi, sampler = SobolSamplerNd(domain))\n",
        "    solver.run(n_samples=1000, steps_per_sample=10, n_interior = 2048, n_boundary = 128, n_terminal = 128)\n",
        "\n",
        "\n",
        "def testExchange():\n",
        "    dim = 2\n",
        "    T = 1\n",
        "    domain = DomainNd(np.array([[0, 100], [20, 100]], dtype=np.float32), T)\n",
        "    vol_vec, ir, dividend_vec, strike = [0.15, 0.1], 0.03, [0.03, 0.02], 50\n",
        "    payoff_func = lambda x: tf.nn.relu(x[:,0] - x[:,1])\n",
        "    multi = 1.3\n",
        "    corr_mat = 0.25 * np.ones((dim, dim), dtype=np.float32)\n",
        "    np.fill_diagonal(corr_mat, 1)\n",
        "    solver = Euro(payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, strike, multi, sampler = SobolSamplerNd(domain))\n",
        "    solver.run(n_samples=500, steps_per_sample=10, n_interior=2048, n_boundary = 128, n_terminal=128, saved_name = \"Exchange\", new_training= False)\n",
        "    #solver.trainAgain(saved_name = \"Exchange\", n_samples=500, steps_per_sample=10, n_interior=2000, n_terminal=100)\n",
        "\n",
        "\n",
        "def test_American():\n",
        "    dim = 1\n",
        "    T = 1\n",
        "    multi = 1\n",
        "    domain = DomainNd(np.array([[0, 100]], dtype=np.float32), T)\n",
        "    vol_vec, ir, dividend_vec, strike = 0.15*np.ones(dim, dtype=np.float32), 0.04, 0.01*np.ones(dim, dtype=np.float32), 50\n",
        "    payoff_func = lambda x: tf.nn.relu(strike - tf.math.reduce_sum(x, axis=1))\n",
        "    #payoff_func = lambda x: tf.nn.relu(tf.math.reduce_sum(x, axis=1) - strike)\n",
        "    corr_mat = 0.25 * np.ones((dim, dim), dtype=np.float32)\n",
        "    np.fill_diagonal(corr_mat, 1)\n",
        "    solver = American(payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, strike, sampler = SobolSamplerNd(domain))\n",
        "    solver.run(n_samples=500, steps_per_sample=10, n_interior=2048, n_boundary = 100 n_terminal=512)\n",
        "\n",
        "def test_heston1():\n",
        "    dim = 1\n",
        "    T = 1\n",
        "    domain = DomainNd(np.array([[0, 100]], dtype=np.float32), T)\n",
        "    vol_vec, ir, dividend_vec, strike = 0.15*np.ones(dim, dtype=np.float32), 0.04, 0.01*np.ones(dim, dtype=np.float32), 50\n",
        "    kappa, theta, xi, rho = 0.5, 0.1, 0.2, 0.3\n",
        "    payoff_func = lambda x: tf.nn.relu(tf.math.reduce_sum(x, axis=1) - strike)\n",
        "    corr_mat = 0.25 * np.ones((dim, dim), dtype=np.float32)\n",
        "    np.fill_diagonal(corr_mat, 1)\n",
        "\n",
        "    solver = EuroHeston(payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, strike, kappa, theta, xi, rho, sampler = SamplerHeston(domain, vol_vec[0], kappa, theta, xi, rho))\n",
        "    solver.run(n_samples=500, steps_per_sample=10, n_interior=2000, n_terminal=250, new_training = False)\n",
        "\n",
        "\n",
        "def test_CEV1():\n",
        "    dim = 1\n",
        "    T = 1\n",
        "    multi = 1.3\n",
        "    domain, multi = DomainNd(np.tile(np.array([0, 100], dtype=np.float32), (dim, 1)), T), 1.3\n",
        "    vol_vec, ir, dividend_vec, strike, beta = 0.15*np.ones(dim, dtype=np.float32), 0.04, 0.01*np.ones(dim, dtype=np.float32), 50, 1.0\n",
        "    payoff_func = lambda x: tf.nn.relu(tf.math.reduce_sum(x, axis=1) - strike)\n",
        "    #payoff_func = lambda x: tf.nn.relu(tf.pow(tf.math.reduce_prod(x, axis=1), 1/dim) - strike)\n",
        "    corr_mat = 0.25 * np.ones((dim, dim), dtype=np.float32)\n",
        "    np.fill_diagonal(corr_mat, 1)\n",
        "    solver = CEV(payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, beta, strike, sampler= SamplerNd(domain, multi))\n",
        "    solver.run(n_samples=5000, steps_per_sample=10, n_interior=2000, n_terminal=100)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def test_euro1d():\n",
        "    dim = 1\n",
        "    T = 1\n",
        "\n",
        "    domain, multi = DomainNd(np.array([[0, 100]], dtype=np.float32), T), 1.3\n",
        "    vol_vec, ir, dividend_vec, strike = 0.1*np.ones(dim, dtype=np.float32), 0.03, 0.02*np.ones(dim, dtype=np.float32), 60\n",
        "    payoff_func = lambda x: tf.nn.relu(tf.math.reduce_sum(x, axis=1) - strike)\n",
        "    corr_mat = 0.25 * np.ones((dim, dim), dtype=np.float32)\n",
        "    np.fill_diagonal(corr_mat, 1)\n",
        "    solver = Euro(payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, strike, multi, sampler = SamplerNdV2(domain, multi))\n",
        "    solver.run(n_samples=30, steps_per_sample=10, n_interior=2000, n_boundary = 100, n_terminal=100, saved_name = 'Euro1d', new_training = False)\n",
        "\n",
        "def test_euro1dAgain():\n",
        "    dim = 1\n",
        "    T = 1\n",
        "    multi = 1.3\n",
        "    domain, multi = DomainNd(np.array([[0, 100]], dtype=np.float32), T), 1.3\n",
        "    vol_vec, ir, dividend_vec, strike = 0.15*np.ones(dim, dtype=np.float32), 0.04, 0.01*np.ones(dim, dtype=np.float32), 50\n",
        "    payoff_func = lambda x: tf.nn.relu(tf.math.reduce_sum(x, axis=1) - strike)\n",
        "    corr_mat = 0.25 * np.ones((dim, dim), dtype=np.float32)\n",
        "    np.fill_diagonal(corr_mat, 1)\n",
        "    solver = Euro(payoff_func, domain, vol_vec, ir, dividend_vec, corr_mat, strike, sampler = SamplerNd(domain, multi))\n",
        "    solver.trainAgain(saved_name = \"Euro1d\", n_samples=5000, steps_per_sample=10, n_interior=2000, n_terminal=100)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "test_American()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcAxmrAGksQo",
        "outputId": "b42348e3-fe66-48df-f081-c5d618f686a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./Euro1d.weights.h5\n"
          ]
        }
      ],
      "source": [
        "!find . -name \"*.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX1FNefvecan"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.integrate as integrate\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Characteristic function for the Heston model\n",
        "def heston_cf(u, S0, K, T, r, q, v0, kappa, theta, sigma, rho):\n",
        "    i = 1j\n",
        "    d = np.sqrt((rho * sigma * i * u - kappa)**2 + (u**2 + i * u) * sigma**2)\n",
        "    g = (kappa - rho * sigma * i * u - d) / (kappa - rho * sigma * i * u + d)\n",
        "\n",
        "    C = r * i * u * T + (kappa * theta) / (sigma**2) * ((kappa - rho * sigma * i * u - d) * T - 2 * np.log((1 - g * np.exp(-d * T)) / (1 - g)))\n",
        "    D = (kappa - rho * sigma * i * u - d) / (sigma**2) * ((1 - np.exp(-d * T)) / (1 - g * np.exp(-d * T)))\n",
        "\n",
        "    return np.exp(C + D * v0 + i * u * np.log(S0 * np.exp(-q * T)))\n",
        "\n",
        "# Integrand functions for P1 and P2\n",
        "def integrand_P1(u, S0, K, T, r, q, v0, kappa, theta, sigma, rho):\n",
        "    return np.real(np.exp(-1j * u * np.log(K)) * heston_cf(u - 1j, S0, K, T, r, q, v0, kappa, theta, sigma, rho) / (1j * u * heston_cf(-1j, S0, K, T, r, q, v0, kappa, theta, sigma, rho)))\n",
        "\n",
        "def integrand_P2(u, S0, K, T, r, q, v0, kappa, theta, sigma, rho):\n",
        "    return np.real(np.exp(-1j * u * np.log(K)) * heston_cf(u, S0, K, T, r, q, v0, kappa, theta, sigma, rho) / (1j * u))\n",
        "\n",
        "# Numerical integration for P1 and P2\n",
        "def P1(S0, K, T, r, q, v0, kappa, theta, sigma, rho):\n",
        "    return 0.5 + (1 / np.pi) * integrate.quad(lambda u: integrand_P1(u, S0, K, T, r, q, v0, kappa, theta, sigma, rho), 0, np.inf)[0]\n",
        "\n",
        "def P2(S0, K, T, r, q, v0, kappa, theta, sigma, rho):\n",
        "    return 0.5 + (1 / np.pi) * integrate.quad(lambda u: integrand_P2(u, S0, K, T, r, q, v0, kappa, theta, sigma, rho), 0, np.inf)[0]\n",
        "\n",
        "# Heston European call price\n",
        "def heston_call_price(S0, K, T, r, q, v0, kappa, theta, sigma, rho):\n",
        "    return S0 * np.exp(-q * T) * P1(S0, K, T, r, q, v0, kappa, theta, sigma, rho) - K * np.exp(-r * T) * P2(S0, K, T, r, q, v0, kappa, theta, sigma, rho)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ey1Mo--vlkcH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import ncx2\n",
        "\n",
        "# Call price under CEV Model\n",
        "\n",
        "def CEVclosed(S0, K, r, q, beta, sigma, t):\n",
        "    z = 2 + 1/(1-beta)\n",
        "    kappa = 2*r/(sigma**2*(1-beta)*(np.exp(2*r*(1-beta)*t)-1))\n",
        "    x = kappa*S0**(2*(1-beta))*np.exp(2*r*(1-beta)*t)\n",
        "    y = kappa*K**(2*(1-beta))\n",
        "    return S0*np.exp(-q*t)*(1-ncx2.cdf(y,z,x))-K*np.exp(-r*t)*ncx2.cdf(x,z-2,y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k0FGEf0JbDu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def AmericanBinom(S0, K, T, r, sig, delta):\n",
        "    N = 2500  # number of periods or number of time steps\n",
        "    payoff = \"put\"  # payoff\n",
        "\n",
        "    dT = float(T) / N  # Delta t\n",
        "    u = np.exp(sig * np.sqrt(dT))  # up factor\n",
        "    d = 1.0 / u  # down factor\n",
        "\n",
        "    V = np.zeros(N + 1)  # initialize the price vector\n",
        "    S_T = np.array([S0 * u**j * d**(N - j) for j in range(N + 1)])  # price S_T at time T\n",
        "\n",
        "    a = np.exp((r - delta) * dT)  # adjusted risk-free compound return\n",
        "    p = (a - d) / (u - d)  # risk-neutral up probability\n",
        "    q = 1.0 - p  # risk-neutral down probability\n",
        "\n",
        "    if payoff == \"call\":\n",
        "        V[:] = np.maximum(S_T - K, 0.0)\n",
        "    elif payoff == \"put\":\n",
        "        V[:] = np.maximum(K - S_T, 0.0)\n",
        "\n",
        "    for i in range(N - 1, -1, -1):\n",
        "        V[:-1] = np.exp(-r * dT) * (p * V[1:] + q * V[:-1])  # the price vector is overwritten at each step\n",
        "        S_T = S_T * u  # it is a tricky way to obtain the price at the previous time step\n",
        "        if payoff == \"call\":\n",
        "            V = np.maximum(V, S_T - K)\n",
        "        elif payoff == \"put\":\n",
        "            V = np.maximum(V, K - S_T)\n",
        "    return V[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwXXVcuFcLLw",
        "outputId": "c8bc73f9-28ac-46a3-ffb3-581eba2cb329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basket Option Price: 10.915120641804958\n",
            "Standard Error: 0.015815959670967\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def monte_carlo_basket_option(S0, K, T, r, sigma, q, correlation_matrix, n_simulations, option_type='call'):\n",
        "    n_assets = len(S0)\n",
        "\n",
        "    # Cholesky decomposition for correlation\n",
        "    L = np.linalg.cholesky(correlation_matrix)\n",
        "\n",
        "    # Simulate asset prices at expiration\n",
        "    prices = np.zeros((n_simulations, n_assets))\n",
        "    for i in range(n_simulations):\n",
        "        z = np.random.normal(size=n_assets)\n",
        "        correlated_randoms = L @ z\n",
        "\n",
        "        for j in range(n_assets):\n",
        "            # Simulate asset price at expiration using geometric Brownian motion\n",
        "            prices[i, j] = S0[j] * np.exp((r - q - 0.5 * sigma**2) * T + sigma * correlated_randoms[j] * np.sqrt(T))\n",
        "\n",
        "    # Calculate the geometric mean of the final prices\n",
        "    geometric_means = np.prod(prices, axis=1) ** (1/n_assets)\n",
        "\n",
        "    # Calculate payoffs\n",
        "    if option_type == 'call':\n",
        "        payoffs = np.maximum(geometric_means - K, 0)\n",
        "    elif option_type == 'put':\n",
        "        payoffs = np.maximum(K - geometric_means, 0)\n",
        "\n",
        "    # Discount payoffs back to present value\n",
        "    discounted_payoffs = np.exp(-r * T) * payoffs\n",
        "\n",
        "    # Calculate option price and standard error\n",
        "    option_price = np.mean(discounted_payoffs)\n",
        "    standard_error = np.std(discounted_payoffs) / np.sqrt(n_simulations)\n",
        "\n",
        "    return option_price, standard_error\n",
        "\n",
        "# Parameters for the 10 asset case\n",
        "n_assets = 10\n",
        "S0 = [60] * n_assets  # Initial prices of the assets\n",
        "K = 50                 # Strike price\n",
        "T = 1                   # Time to maturity in years\n",
        "r = 0.04               # Risk-free interest rate\n",
        "q = 0.01               # Dividend yield\n",
        "sigma = 0.15           # Volatility of the assets\n",
        "rho = 0.25             # Correlation\n",
        "\n",
        "# Constructing the correlation matrix\n",
        "correlation_matrix = np.full((n_assets, n_assets), rho)\n",
        "np.fill_diagonal(correlation_matrix, 1)\n",
        "\n",
        "n_simulations = 100000  # Number of simulations\n",
        "\n",
        "# Pricing the basket option\n",
        "price, se = monte_carlo_basket_option(S0, K, T, r, sigma, q, correlation_matrix, n_simulations, option_type='call')\n",
        "print(f'Basket Option Price: {price}')\n",
        "print(f'Standard Error: {se}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_B9xoCkjilC"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1jTdbOzmbST8YiJXfRhuQVN9OnM-B_lDS",
      "authorship_tag": "ABX9TyM9WiBm9vqobczcNtWtcD99",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}